{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XZFrKWHwEf7h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce RTX 3090 (UUID: GPU-5371946b-bc7a-8404-76f2-94eebc42c1b7)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m../../images/png\u001b[0m\n",
      "├── \u001b[01;34mCollection1\u001b[0m\n",
      "│   └── \u001b[01;34mBAYC\u001b[0m\n",
      "└── \u001b[01;34mCollection2\u001b[0m\n",
      "    └── \u001b[01;34mEAPES\u001b[0m\n",
      "\n",
      "4 directories\n"
     ]
    }
   ],
   "source": [
    "!tree -d ../../images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install numpy -q\n",
    "!pip3 install torch -q\n",
    "!pip3 install torchvision -q\n",
    "!pip3 install matplotlib -q\n",
    "!pip3 install tqdm -q\n",
    "!pip3 install ipywidgets -q\n",
    "!pip3 install opencv-python -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RC5YKYGuEf7n"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_ssim\n",
    "from torchvision.models.vgg import vgg16\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "# manualSeed = 42\n",
    "manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "print(\"Random Seed: \", manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Read_dataset_h5(data.Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        super(Read_dataset_h5, self).__init__()\n",
    "        hf = h5py.File(file_path)\n",
    "        self.input = hf.get('input')\n",
    "        self.label = hf.get('label')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return torch.from_numpy(self.input[index,:,:,:]).float(), torch.from_numpy(self.label[index,:,:,:]).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.input.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.prelu = nn.PReLU()\n",
    "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.conv1(x)\n",
    "        residual = self.bn1(residual)\n",
    "        residual = self.prelu(residual)\n",
    "        residual = self.conv2(residual)\n",
    "        residual = self.bn2(residual)\n",
    "\n",
    "        return x + residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4HEAwzAFEf7r"
   },
   "outputs": [],
   "source": [
    "class G_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(G_Net, self).__init__()\n",
    "        self.input = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=9, padding=4),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "        self.ResidualBlock1 = ResidualBlock(64)\n",
    "        self.ResidualBlock2 = ResidualBlock(64)\n",
    "        self.ResidualBlock3 = ResidualBlock(64)\n",
    "        self.ResidualBlock4 = ResidualBlock(64)\n",
    "        self.ResidualBlock5 = ResidualBlock(64)\n",
    "        self.output_residual = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "        self.pixel_shuffle = nn.Sequential(\n",
    "            nn.Conv2d(64, 64 * 2 ** 2, kernel_size=3, padding=1),\n",
    "            nn.PixelShuffle(2),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "        self.pixel_shuffle2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64 * 2 ** 2, kernel_size=3, padding=1),\n",
    "            nn.PixelShuffle(2),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "        self.output =  nn.Sequential(\n",
    "            nn.Conv2d(64, 3, kernel_size=9, padding=4),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        input = self.input(x)\n",
    "        ResidualBlock1 = self.ResidualBlock1(input)\n",
    "        ResidualBlock2 = self.ResidualBlock2(ResidualBlock1)\n",
    "        ResidualBlock3 = self.ResidualBlock3(ResidualBlock2)\n",
    "        ResidualBlock4 = self.ResidualBlock4(ResidualBlock3)\n",
    "        ResidualBlock5 = self.ResidualBlock5(ResidualBlock4)\n",
    "        output_residual = self.output_residual(ResidualBlock5)\n",
    "        pixel_shuffle = self.pixel_shuffle(output_residual + input)\n",
    "        pixel_shuffle2 = self.pixel_shuffle2(pixel_shuffle)\n",
    "        output = self.output(pixel_shuffle2)\n",
    "        output = (output+1)/2\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(D_Net, self).__init__()\n",
    "        self.Net = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(512, 1024, kernel_size=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(1024, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.Net(x)\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GeneratorLoss, self).__init__()\n",
    "        vgg = vgg16(pretrained=True)\n",
    "        vgg_loss = nn.Sequential(*list(vgg.features)[:31]).eval()\n",
    "        for param in vgg_loss.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.vgg_loss = vgg_loss\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.cross_entropy = nn.BCELoss()\n",
    "\n",
    "    def forward(self, fake_rate, SR, HR):\n",
    "        # MSE Loss\n",
    "        MSE_loss = self.mse_loss(SR, HR)\n",
    "        # VGG Loss\n",
    "        VGG_loss = self.mse_loss(self.vgg_loss(SR), self.vgg_loss(HR))\n",
    "        # Adversarial Loss\n",
    "        Adversarial_loss = self.cross_entropy(fake_rate,torch.ones(fake_rate.size(0)).cuda())\n",
    "        return MSE_loss + 6e-3 * VGG_loss + 1e-3 * Adversarial_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiscriminatorLoss, self).__init__()\n",
    "        self.cross_entropy = nn.BCELoss()\n",
    "\n",
    "    def forward(self, fake_rate, real_rate):\n",
    "        # Fake_img Correct Rate\n",
    "        Fake_img_CR = self.cross_entropy(fake_rate,torch.zeros(fake_rate.size(0)).cuda())\n",
    "        # Real_img Correct Rate\n",
    "        Real_img_CR = self.cross_entropy(real_rate,torch.ones(real_rate.size(0)).cuda())\n",
    "        return Fake_img_CR + Real_img_CR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global opt, G_Net, D_Net , G_optim, D_optim\n",
    "epoch = 1\n",
    "opt = parser.parse_args() # opt < parser\n",
    "print(opt)\n",
    "\n",
    "print(\"===> Setting GPU\")\n",
    "cuda = opt.cuda\n",
    "if cuda:\n",
    "    print(\"=> use gpu id: '{}'\".format(opt.gpus))\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = opt.gpus # set gpu\n",
    "    if not torch.cuda.is_available():\n",
    "            raise Exception(\"No GPU found or Wrong gpu id, please run without --cuda\")\n",
    "\n",
    "opt.seed = random.randint(1, 10000)\n",
    "print(\"Random Seed: \", opt.seed)\n",
    "torch.manual_seed(opt.seed) # set seed\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(opt.seed)\n",
    "\n",
    "cudnn.benchmark = True # find optimal algorithms for hardware\n",
    "\n",
    "print(\"===> Loading datasets\")\n",
    "train_set = Read_dataset_h5(\"data/train.h5\")\n",
    "training_data_loader = DataLoader(dataset=train_set, num_workers=opt.threads,\n",
    "    batch_size=opt.batchSize, shuffle=True) # read to DataLoader\n",
    "\n",
    "print(\"===> Building model\")\n",
    "G_Net = G_Net()\n",
    "D_Net = D_Net()\n",
    "G_Loss = GeneratorLoss()\n",
    "D_Loss = DiscriminatorLoss()\n",
    "\n",
    "# optionally copy weights from a checkpoint\n",
    "if opt.pretrained:\n",
    "    if os.path.isfile(opt.pretrained):\n",
    "        print(\"=> loading model '{}'\".format(opt.pretrained))\n",
    "        checkpoint = torch.load(opt.pretrained)\n",
    "        G_Net.load_state_dict(checkpoint['G_Net_state_dict'])\n",
    "        D_Net.load_state_dict(checkpoint['D_Net_state_dict'])\n",
    "        epoch = checkpoint['epoch'] + 1 # load model\n",
    "    else:\n",
    "        print(\"=> no model found at '{}'\".format(opt.pretrained))\n",
    "\n",
    "if cuda:\n",
    "    G_Net = G_Net.cuda()\n",
    "    D_Net = D_Net.cuda()\n",
    "    G_Loss = G_Loss.cuda()\n",
    "    D_Loss = D_Loss.cuda() # set model&loss for use gpu\n",
    "\n",
    "print(\"===> Setting Optimizer\")\n",
    "G_optim = optim.Adam(G_Net.parameters())\n",
    "D_optim = optim.Adam(D_Net.parameters())\n",
    "\n",
    "if opt.pretrained:\n",
    "    if os.path.isfile(opt.pretrained):\n",
    "        G_optim.load_state_dict(checkpoint['G_optim_state_dict'])\n",
    "        D_optim.load_state_dict(checkpoint['D_optim_state_dict'])\n",
    "        print(\"===> Setting Pretrained Optimizer\")\n",
    "\n",
    "print(\"=> start epoch '{}'\".format(epoch))\n",
    "print(\"===> Training\")\n",
    "for epoch_ in range(epoch, opt.nEpochs + 1):\n",
    "    print(\"===>  Start epoch {} #################################################################\".format(epoch_))\n",
    "    G_Net.train()\n",
    "    D_Net.train()\n",
    "    for _, (input, label) in enumerate(training_data_loader):\n",
    "        HR = Variable(label)/255\n",
    "        LR = Variable(input)/255\n",
    "        if torch.cuda.is_available():\n",
    "            HR = HR.cuda()\n",
    "            LR = LR.cuda()\n",
    "        fake_img = G_Net(LR)\n",
    "\n",
    "        # Train Discriminator model\n",
    "        D_Net.zero_grad()\n",
    "        real_rate = D_Net(HR)\n",
    "        fake_rate = D_Net(fake_img)\n",
    "        d_loss = D_Loss(fake_rate, real_rate)\n",
    "        d_loss.backward()\n",
    "        D_optim.step()\n",
    "\n",
    "        # Train Generator model\n",
    "        G_Net.zero_grad()\n",
    "        g_loss = G_Loss(fake_rate, fake_img, HR)\n",
    "        g_loss.backward()\n",
    "        G_optim.step()\n",
    "\n",
    "        # loss 출력\n",
    "        if _%10 == 0:\n",
    "            print(\"===> Epoch[[{}]({}/{})]: D_Loss : {:.10f}, G_Loss : {:.10f}, SSIM : {:.10f}\".format(epoch_, _, len(training_data_loader), d_loss, g_loss, pytorch_ssim.ssim(HR, fake_img)))\n",
    "\n",
    "    model_out_path = \"checkpoint/\" + \"SRGAN_Adam_epoch_{}.tar\".format(epoch_)\n",
    "    if not os.path.exists(\"checkpoint/\"):\n",
    "        os.makedirs(\"checkpoint/\")\n",
    "    torch.save({\n",
    "            'epoch': epoch_,\n",
    "            'G_Net_state_dict': G_Net.state_dict(),\n",
    "            'D_Net_state_dict': D_Net.state_dict(),\n",
    "            'G_optim_state_dict': G_optim.state_dict(),\n",
    "            'D_optim_state_dict': D_optim.state_dict()\n",
    "            }, model_out_path)\n",
    "    print(\"Checkpoint has been saved to the {}\".format(model_out_path))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "SR_PT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "07d9f5e508bec3c3752adee78722f681196014f9755899b43f3e274f86dd0f82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
